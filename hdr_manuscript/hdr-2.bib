@misc{williams2012,
abstract = {Open PHACTS is a public-private partnership between academia, publishers, small and medium sized enterprises and pharmaceutical companies. The goal of the project is to deliver and sustain an 'open pharmacological space' using and enhancing state-of-the-art semantic web standards and technologies. It is focused on practical and robust applications to solve specific questions in drug discovery research. OPS is intended to facilitate improvements in drug discovery in academia and industry and to support open innovation and in-house non-public drug discovery research. This paper lays out the challenges and how the Open PHACTS project is hoping to address these challenges technically and socially. {\textcopyright} 2012 Elsevier Ltd.},
author = {Williams, Antony J. and Harland, Lee and Groth, Paul and Pettifer, Stephen and Chichester, Christine and Willighagen, Egon L. and Evelo, Chris T. and Blomberg, Niklas and Ecker, Gerhard and Goble, Carole and Mons, Barend},
booktitle = {Drug Discovery Today},
doi = {10.1016/j.drudis.2012.05.016},
isbn = {1878-5832 (Electronic)$\backslash$r1359-6446 (Linking)},
issn = {13596446},
number = {21-22},
pages = {1188--1198},
pmid = {22683805},
title = {{Open PHACTS: Semantic interoperability for drug discovery}},
volume = {17},
year = {2012}
}
@misc{ngoc:lirmm-01274707,
annote = {Poster},
author = {{LE Ngoc}, Luyen and Jouannic, St{\'{e}}phane and Gantet, Pascal and Larmande, Pierre},
howpublished = {JOBIM: Journ{\{}{\'{e}}{\}}es Ouvertes Biologie Informatique Math{\{}{\'{e}}{\}}matiques},
keywords = {Agronomic data,Bioinformatic application,Database Applications,Distributed Application},
title = {{Development of a generic indexing tool to optimize the use of biological data}},
url = {http://hal-lirmm.ccsd.cnrs.fr/lirmm-01274707},
year = {2015}
}
@article{Sallaud2003a,
abstract = {We investigated the potential of an improved Agrobacterium tumefaciens-mediated transformation procedure of japonica rice ( Oryza sativa L.) for generating large numbers of T-DNA plants that are required for functional analysis of this model genome. Using a T-DNA construct bearing the hygromycin resistance ( hpt), green fluorescent protein ( gfp) and beta-glucuronidase ( gusA) genes, each individually driven by a CaMV 35S promoter, we established a highly efficient seed-embryo callus transformation procedure that results both in a high frequency (75-95{\%}) of co-cultured calli yielding resistant cell lines and the generation of multiple (10 to more than 20) resistant cell lines per co-cultured callus. Efficiencies ranged from four to ten independent transformants per co-cultivated callus in various japonica cultivars. We further analysed the T-DNA integration patterns within a population of more than 200 transgenic plants. In the three cultivars studied, 30-40{\%} of the T(0) plants were found to have integrated a single T-DNA copy. Analyses of segregation for hygromycin resistance in T(1) progenies showed that 30-50{\%} of the lines harbouring multiple T-DNA insertions exhibited hpt gene silencing, whereas only 10{\%} of lines harbouring a single T-DNA insertion was prone to silencing. Most of the lines silenced for hpt also exhibited apparent silencing of the gus and gfp genes borne by the T-DNA. The genomic regions flanking the left border of T-DNA insertion points were recovered in 477 plants and sequenced. Adapter-ligation Polymerase chain reaction analysis proved to be an efficient and reliable method to identify these sequences. By homology search, 77 T-DNA insertion sites were localized on BAC/PAC rice Nipponbare sequences. The influence of the organization of T-DNA integration on subsequent identification of T-DNA insertion sites and gene expression detection systems is discussed.},
author = {Sallaud, C and Meynard, D and van Boxtel, J and Gay, C and B{\`{e}}s, M and Brizard, J P and Larmande, P and Ortega, D and Raynal, M and Portefaix, M and Ouwerkerk, P B F and Rueb, S and Delseny, M and Guiderdoni, E},
doi = {10.1007/s00122-002-1184-x},
file = {:Users/plarmande/Documents/Mendeley Desktop/Sallaud et al/TAG. Theoretical and Applied Genetics. Theoretische Und Angewandte Genetik/Sallaud et al.{\_}2003{\_}Highly efficient production and characterization of T-DNA plants for rice ( Oryza sativa L.) functional genomics.html:html},
issn = {0040-5752},
journal = {TAG. Theoretical and Applied Genetics. Theoretische Und Angewandte Genetik},
keywords = {Base Sequence,Caulimovirus,DNA Primers,DNA- Bacterial,Genome- Plant,Genomics,Glucuronidase,Green Fluorescent Proteins,Luminescent Proteins,Oryza sativa,Promoter Regions- Genetic,Rhizobium radiobacter,Transformation- Genetic},
mendeley-tags = {Base Sequence,Caulimovirus,DNA Primers,DNA- Bacterial,Genome- Plant,Genomics,Glucuronidase,Green Fluorescent Proteins,Luminescent Proteins,Oryza sativa,Promoter Regions- Genetic,Rhizobium radiobacter,Transformation- Genetic},
month = {may},
number = {8},
pages = {1396--408},
title = {{Highly efficient production and characterization of T-DNA plants for rice ( Oryza sativa L.) functional genomics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12677401 http://www.ncbi.nlm.nih.gov/pubmed/12677401?dopt=AbstractPlus},
volume = {106},
year = {2003}
}
@article{Pugh2004,
abstract = {A linkage map of cacao based on codominant markers has been constructed by integrating 201 new simple sequence repeats (SSR) developed in this study with a number of isoenzymes, restriction fragment length polymorphisms (RFLP), microsatellite markers and resistance and defence gene analogs (Rgenes-RFLP) previously mapped in cacao. A genomic library enriched for (GA)(n) and (CA)(n) was constructed, and 201 new microsatellite loci were mapped on 135 individuals from the same mapping population used to establish the first reference maps. This progeny resulted from a cross between two heterozygous cacao clones: an Upper-Amazon Forastero (UPA 402) and a Trinitario (UF 676). The new map contains 465 markers (268 SSRs, 176 RFLPs, five isoenzymes and 16 Rgenes-RFLP) arranged in ten linkage groups corresponding to the haploid chromosome number of cacao. Its length is 782.8 cM, with an average interval distance between markers of 1.7 cM. The new microsatellite markers were distributed throughout all linkage groups of the map, but their distribution was not random. The length of the map established with only SSRs was 769.6 cM, representing 94.8{\%} of the total map. The current level of genome coverage is approximately one microsatellite every 3 cM. This new reference map provides a set of useful markers that is transferable across different mapping populations and will allow the identification and comparison of the most important regions involved in the variation of the traits of interest and the development of marker-assisted selection strategies.},
author = {Pugh, T. and Fouet, O. and Risterucci, A. M. and Brottier, P. and Abouladze, M. and Deletrez, C. and Courtois, B. and Clement, D. and Larmande, P. and N'Goran, J. A K and Lanaud, C.},
doi = {10.1007/s00122-003-1533-4},
file = {:Users/plarmande/Documents/Mendeley Desktop/Pugh et al/Theor Appl Genet/Pugh et al.{\_}2004{\_}A new cacao linkage map based on codominant markers development and integration of 201 new microsatellite markers.html:html},
issn = {0040-5752},
journal = {Theor Appl Genet},
keywords = {Cacao,Cacao- Chromosome Mapping- Crosses,Chromosome Mapping,Crosses- Genetic,Genetic- DNA Primers- Genomic Library- Microsatell,Genetic- Polymorphism,Genomic Library,Microsatellite Repeats,Polymorphism- Genetic,Polymorphism- Restriction Fragment Length,Restriction Fragment Length},
mendeley-tags = {Cacao,Cacao- Chromosome Mapping- Crosses,Chromosome Mapping,Crosses- Genetic,Genetic- DNA Primers- Genomic Library- Microsatell,Genetic- Polymorphism,Genomic Library,Microsatellite Repeats,Polymorphism- Genetic,Polymorphism- Restriction Fragment Length,Restriction Fragment Length},
month = {apr},
number = {6},
pages = {1151--61},
shorttitle = {A new cacao linkage map based on codominant marker},
title = {{A new cacao linkage map based on codominant markers: development and integration of 201 new microsatellite markers}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14760486 http://www.ncbi.nlm.nih.gov/pubmed/14760486?dopt=AbstractPlus http://dx.doi.org/10.1007/s00122-003-1533-4},
volume = {108},
year = {2004}
}
@article{Sallaud2003,
abstract = {We investigated the potential of an improved Agrobacterium tumefaciens-mediated transformation procedure of japonica rice ( Oryza sativa L.) for generating large numbers of T-DNA plants that are required for functional analysis of this model genome. Using a T-DNA construct bearing the hygromycin resistance ( hpt), green fluorescent protein ( gfp) and beta-glucuronidase ( gusA) genes, each individually driven by a CaMV 35S promoter, we established a highly efficient seed-embryo callus transformation procedure that results both in a high frequency (75-95{\%}) of co-cultured calli yielding resistant cell lines and the generation of multiple (10 to more than 20) resistant cell lines per co-cultured callus. Efficiencies ranged from four to ten independent transformants per co-cultivated callus in various japonica cultivars. We further analysed the T-DNA integration patterns within a population of more than 200 transgenic plants. In the three cultivars studied, 30-40{\%} of the T(0) plants were found to have integrated a single T-DNA copy. Analyses of segregation for hygromycin resistance in T(1) progenies showed that 30-50{\%} of the lines harbouring multiple T-DNA insertions exhibited hpt gene silencing, whereas only 10{\%} of lines harbouring a single T-DNA insertion was prone to silencing. Most of the lines silenced for hpt also exhibited apparent silencing of the gus and gfp genes borne by the T-DNA. The genomic regions flanking the left border of T-DNA insertion points were recovered in 477 plants and sequenced. Adapter-ligation Polymerase chain reaction analysis proved to be an efficient and reliable method to identify these sequences. By homology search, 77 T-DNA insertion sites were localized on BAC/PAC rice Nipponbare sequences. The influence of the organization of T-DNA integration on subsequent identification of T-DNA insertion sites and gene expression detection systems is discussed.},
author = {Sallaud, C and Meynard, D and van Boxtel, J and Gay, C and B{\`{e}}s, M and Brizard, J P and Larmande, P and Ortega, D and Raynal, M and Portefaix, M and Ouwerkerk, P B F and Rueb, S and Delseny, M and Guiderdoni, E},
doi = {10.1007/s00122-002-1184-x},
file = {:Users/plarmande/Documents/Mendeley Desktop/Sallaud et al/TAG. Theoretical and Applied Genetics. Theoretische Und Angewandte Genetik/Sallaud et al.{\_}2003{\_}Highly efficient production and characterization of T-DNA plants for rice ( Oryza sativa L.) functional genomics.html:html},
issn = {0040-5752},
journal = {TAG. Theoretical and Applied Genetics. Theoretische Und Angewandte Genetik},
keywords = {Base Sequence,Caulimovirus,DNA Primers,DNA- Bacterial,Genome- Plant,Genomics,Glucuronidase,Green Fluorescent Proteins,Luminescent Proteins,Oryza sativa,Promoter Regions- Genetic,Rhizobium radiobacter,Transformation- Genetic},
mendeley-tags = {Base Sequence,Caulimovirus,DNA Primers,DNA- Bacterial,Genome- Plant,Genomics,Glucuronidase,Green Fluorescent Proteins,Luminescent Proteins,Oryza sativa,Promoter Regions- Genetic,Rhizobium radiobacter,Transformation- Genetic},
month = {may},
number = {8},
pages = {1396--408},
title = {{Highly efficient production and characterization of T-DNA plants for rice ( Oryza sativa L.) functional genomics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12677401 http://www.ncbi.nlm.nih.gov/pubmed/12677401?dopt=AbstractPlus},
volume = {106},
year = {2003}
}
@inproceedings{venkatesan2015towards,
author = {Venkatesan, Aravind and {El Hassouni}, Nordine and Phillipe, Florian and Pommier, Cyril and Quesneville, Hadi and Ruiz, Manuel and Larmande, Pierre},
booktitle = {APIA'15: premiere Conference Applications Pratiques de l'Intelligence Artificielle},
title = {{Towards efficient data integration and knowledge management in the Agronomic domain}},
year = {2015}
}
@inproceedings{DBLP:conf/wims/LuyenTVNL16,
author = {{Le Ngoc}, Luyen and Tireau, Anne and Venkatesan, Aravind and Neveu, Pascal and Larmande, Pierre},
booktitle = {Proceedings of the 6th International Conference on Web Intelligence, Mining and Semantics, WIMS 2016, Nimes, France, June 13-15, 2016},
doi = {10.1145/2912845.2912869},
isbn = {978-1-4503-4056-4},
pages = {27:1----27:9},
publisher = {ACM},
title = {{Development of a knowledge system for Big Data: Case study to plant phenotyping data}},
url = {http://doi.acm.org/10.1145/2912845.2912869},
year = {2016}
}
@article{wollbrett2013clever,
abstract = {BACKGROUND:In recent years, a large amount of "-omics" data have been produced. However, these data are stored in many different species-specific databases that are managed by different institutes and laboratories. Biologists often need to find and assemble data from disparate sources to perform certain analyses. Searching for these data and assembling them is a time-consuming task. The Semantic Web helps to facilitate interoperability across databases. A common approach involves the development of wrapper systems that map a relational database schema onto existing domain ontologies. However, few attempts have been made to automate the creation of such wrappers.},
author = {Wollbrett, Julien and Larmande, Pierre and de Lamotte, Fr{\'{e}}d{\'{e}}ric and Ruiz, Manuel},
doi = {10.1186/1471-2105-14-126},
file = {:Users/plarmande/Documents/Mendeley Desktop/Wollbrett et al/BMC bioinformatics/Wollbrett et al.{\_}2013{\_}Clever generation of rich SPARQL queries from annotated relational schema application to Semantic Web Service crea.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {semantic web},
mendeley-tags = {semantic web},
number = {1},
pages = {126--141},
publisher = {BioMed Central},
title = {{Clever generation of rich SPARQL queries from annotated relational schema: application to Semantic Web Service creation for biological databases}},
url = {http://www.biomedcentral.com/1471-2105/14/126},
volume = {14},
year = {2013}
}
@article{Sempere2016,
abstract = {BACKGROUND Exploring the structure of genomes and analyzing their evolution is essential to understanding the ecological adaptation of organisms. However, with the large amounts of data being produced by next-generation sequencing, computational challenges arise in terms of storage, search, sharing, analysis and visualization. This is particularly true with regards to studies of genomic variation, which are currently lacking scalable and user-friendly data exploration solutions. DESCRIPTION Here we present Gigwa, a web-based tool that provides an easy and intuitive way to explore large amounts of genotyping data by filtering it not only on the basis of variant features, including functional annotations, but also on genotype patterns. The data storage relies on MongoDB, which offers good scalability properties. Gigwa can handle multiple databases and may be deployed in either single- or multi-user mode. In addition, it provides a wide range of popular export formats. CONCLUSIONS The Gigwa application is suitable for managing large amounts of genomic variation data. Its user-friendly web interface makes such processing widely accessible. It can either be simply deployed on a workstation or be used to provide a shared data portal for a given community of researchers.},
author = {Semp{\'{e}}r{\'{e}}, Guilhem and Philippe, Florian and Dereeper, Alexis and Ruiz, Manuel and Sarah, Gautier and Larmande, Pierre},
doi = {10.1186/s13742-016-0131-8},
file = {:Users/plarmande/Documents/Mendeley Desktop/Semp{\'{e}}r{\'{e}} et al/Gigascience/Semp{\'{e}}r{\'{e}} et al.{\_}2016{\_}Gigwa—Genotype investigator for genome- wide analyses.pdf:pdf},
issn = {2047-217X},
journal = {GigaScience},
keywords = {Genomic variations,HapMap,INDEL,MongoDB,NoSQL,SNP,VCF,Web interface},
pages = {25},
pmid = {27267926},
title = {{Gigwa-Genotype investigator for genome-wide analyses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27267926 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4897896},
volume = {5},
year = {2016}
}
@article{DzaleYeumo2017,
author = {{Dzale Yeumo}, Esther and Alaux, Michael and Arnaud, Elizabeth and Aubin, Sophie and Baumann, Ute and Buche, Patrice and Cooper, Laurel and {\'{C}}wiek-Kupczy{\'{n}}ska, Hanna and Davey, Robert P. and Fulss, Richard Allan and Jonquet, Clement and Laporte, Marie-Ang{\'{e}}lique and Larmande, Pierre and Pommier, Cyril and Protonotarios, Vassilis and Reverte, Carmen and Shrestha, Rosemary and Subirats, Imma and Venkatesan, Aravind and Whan, Alex and Quesneville, Hadi},
doi = {10.12688/f1000research.12234.1},
file = {:Users/plarmande/Documents/Mendeley Desktop/Dzale Yeumo et al/F1000Research/Dzale Yeumo et al.{\_}2017{\_}Developing data interoperability using standards A wheat community use case.pdf:pdf},
issn = {2046-1402},
journal = {F1000Research},
month = {oct},
pages = {1843},
title = {{Developing data interoperability using standards: A wheat community use case}},
url = {https://f1000research.com/articles/6-1843/v1},
volume = {6},
year = {2017}
}
@article{AL-Tam2013,
author = {AL-Tam, Faroq and Adam, Helene and Anjos, Ant{\'{o}}nio and Lorieux, Mathias and Larmande, Pierre and Ghesqui{\`{e}}re, Alain and Jouannic, Stefan and Shahbazkia, Hamid},
doi = {10.1186/1471-2229-13-122},
issn = {1471-2229},
journal = {BMC Plant Biology},
language = {en},
number = {1},
pages = {122},
shorttitle = {P-TRAP},
title = {{P-TRAP: a Panicle Trait Phenotyping tool}},
url = {http://www.biomedcentral.com/1471-2229/13/122},
volume = {13},
year = {2013}
}
@article{Larmande2008b,
abstract = {To organize data resulting from the phenotypic characterization of a library of 30,000 T-DNA enhancer trap (ET) insertion lines of rice (Oryza sativa L cv. Nipponbare), we developed the Oryza Tag Line (OTL) database (http://urgi.versailles.inra.fr/OryzaTagLine/). OTL structure facilitates forward genetic search for specific phenotypes, putatively resulting from gene disruption, and/or for GUSA or GFP reporter gene expression patterns, reflecting ET-mediated endogenous gene detection. In the latest version, OTL gathers the detailed morpho-physiological alterations observed during field evaluation and specific screens in a first set of 13,928 lines. Detection of GUS or GFP activity in specific organ/tissues in a subset of the library is also provided. Search in OTL can be achieved through trait ontology category, organ and/or developmental stage, keywords, expression of reporter gene in specific organ/tissue as well as line identification number. OTL now contains the description of 9721 mutant phenotypic traits observed in 2636 lines and 1234 GUS or GFP expression patterns. Each insertion line is documented through a generic passport data including production records, seed stocks and FST information. 8004 and 6101 of the 13,928 lines are characterized by at least one T-DNA and one Tos17 FST, respectively that OTL links to the rice genome browser OryGenesDB.},
author = {Larmande, Pierre and Gay, C{\'{e}}line and Lorieux, Mathias and P{\'{e}}rin, Christophe and Bouniol, Matthieu and Droc, Ga{\"{e}}tan and Sallaud, Christophe and Perez, Pascual and Barnola, Isabelle and Biderre-petit, Corinne and Martin, J{\'{e}}r{\^{o}}me and Morel, Jean Beno{\^{i}}t and Johnson, Alexander A T and Bourgis, Fabienne and Ghesqui{\`{e}}re, Alain and Ruiz, Manuel and Courtois, Brigitte and Guiderdoni, Emmanuel},
doi = {10.1093/nar/gkm762},
file = {:Users/plarmande/Documents/Mendeley Desktop/Larmande et al/Nucleic Acids Research/Larmande et al.{\_}2008{\_}Oryza Tag Line, a phenotypic mutant database for the G{\'{e}}noplante rice insertion line library.pdf:pdf},
isbn = {1362-4962 (Electronic)
0305-1048 (Linking)},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {SUPPL. 1},
pages = {1022--1027},
pmid = {17947330},
title = {{Oryza Tag Line, a phenotypic mutant database for the G{\'{e}}noplante rice insertion line library}},
volume = {36},
year = {2008}
}
@inproceedings{Luyen:2016:DKS:2912845.2912869,
address = {New York, NY, USA},
author = {Luyen, L E Ngoc and Tireau, Anne and Venkatesan, Aravind and Neveu, Pascal and Larmande, Pierre},
booktitle = {Proceedings of the 6th International Conference on Web Intelligence, Mining and Semantics},
doi = {10.1145/2912845.2912869},
isbn = {978-1-4503-4056-4},
keywords = {Benchmark,Big Data,Inference,Knowledge base,NoSQL,Ontology,Reasoning,SPARQL,Triplestore,xR2RML},
pages = {27:1----27:9},
publisher = {ACM},
series = {WIMS '16},
title = {{Development of a Knowledge System for Big Data: Case Study to Plant Phenotyping Data}},
url = {http://doi.acm.org/10.1145/2912845.2912869},
year = {2016}
}
@article{Droc2009,
abstract = {OryGenesDB (http://orygenesdb.cirad.fr/index.html) is a database developed for rice reverse genetics. OryGenesDB contains FSTs (flanking sequence tags) of various mutagens and functional genomics data, collected from both international insertion collections and the literature. The current release of OryGenesDB contains 171,000 FSTs, and annotations divided among 10 specific categories, totaling 78 annotation layers. Several additional tools have been added to the main interface; these tools enable the user to retrieve FSTs and design probes to analyze insertion lines. The major innovation of OryGenesDB 2008, besides updating the data and tools, is a new tool, Orylink, which was developed to speed up rice functional genomics by taking advantage of the resources developed in two related databases, Oryza Tag Line and GreenPhylDB. Orylink was designed to field complex queries across these three databases and store both the queries and their results in an intuitive manner. Orylink offers a simple and powerful virtual workbench for functional genomics. Alternatively, the Web services developed for Orylink can be used independently of its Web interface, increasing the interoperability between these different bioinformatics applications.},
author = {Droc, Ga{\"{e}}tan and P{\'{e}}rin, Christophe and Fromentin, S{\'{e}}bastien and Larmande, Pierre},
doi = {10.1093/nar/gkn821},
file = {:Users/plarmande/Documents/Mendeley Desktop/Droc et al/Nucleic Acids Research/Droc et al.{\_}2009{\_}OryGenesDB 2008 update database interoperability for functional genomics of rice.html:html},
issn = {1362-4962},
journal = {Nucleic Acids Research},
month = {jan},
number = {Database issue},
pages = {D992--5},
shorttitle = {OryGenesDB 2008 update},
title = {{OryGenesDB 2008 update: database interoperability for functional genomics of rice}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19036791 http://www.ncbi.nlm.nih.gov/pubmed/19036791?ordinalpos=1{\&}itool=EntrezSystem2.PEntrez.Pubmed.Pubmed{\_}ResultsPanel.Pubmed{\_}DefaultReportPanel.Pubmed{\_}RVDocSum},
volume = {37},
year = {2009}
}
@article{Larmande2007,
abstract = {Les recherches que nous pr{\'{e}}sentons dans ce m{\'{e}}moire s'inscrivent dans le cadre des probl{\'{e}}matiques d'int{\'{e}}gration de donn{\'{e}}es h{\'{e}}t{\'{e}}rog{\`{e}}nes en g{\'{e}}nomique fonctionnelle v{\'{e}}g{\'{e}}tale. La g{\'{e}}nomique fonctionnelle se d{\'{e}}finit en biologie comme un cadre dans lequel plusieurs disciplines et techniques participent {\`{a}} la d{\'{e}}couverte de la fonction des g{\`{e}}nes. Elle g{\'{e}}n{\`{e}}re un volume important de donn{\'{e}}es que les scientifiques g{\`{e}}rent de mani{\`{e}}res diverses. Or de nombreuses sources de donn{\'{e}}es, qu'elles soient compl{\'{e}}mentaires ou chevauchantes, sont n{\'{e}}cessaires pour enrichir les informations sur la fonction des g{\`{e}}nes. Le probl{\`{e}}me est qu'elles sont stock{\'{e}}es de mani{\`{e}}re distribu{\'{e}}es, autonomes avec plusieurs niveaux d'h{\'{e}}t{\'{e}}rog{\'{e}}n{\'{e}}it{\'{e}}, laissant le biologiste chercher l'information et int{\'{e}}grer les r{\'{e}}sultats manuellement. L'objectif de cette th{\`{e}}se est de permettre aux scientifiques d'acc{\'{e}}der de mani{\`{e}}re transparente aux informations issues de plusieurs sources de donn{\'{e}}es de g{\'{e}}nomique fonctionnelle. Pour cela nous nous proposons d'aborder deux approches afin d'en {\'{e}}valuer les avantages et les inconv{\'{e}}nients. Premi{\`{e}}rement nous proposons l'int{\'{e}}gration de sources {\`{a}} travers l'adaptation d'un syst{\`{e}}me de m{\'{e}}diation de donn{\'{e}}es et de programmes : Le Select. Successeur de DISCO, Le Select permet l'int{\'{e}}gration de sources de donn{\'{e}}es h{\'{e}}t{\'{e}}rog{\`{e}}nes et distribu{\'{e}}es avec un mod{\`{e}}le pivot relationnel. Deuxi{\`{e}}mement, nous proposons la cr{\'{e}}ation d'un environnement utilisateur personnalis{\'{e}} int{\'{e}}grant les sources {\`{a}} travers des encha{\^{i}}nements de services Web. Ce syst{\`{e}}me est bas{\'{e}} sur l'application BioMOBY et son annuaire de services bioinformatiques. Pour conclure, fort de l'exp{\'{e}}rience men{\'{e}}e sur l'int{\'{e}}gration et le partage, nous proposons une m{\'{e}}thodologie adapt{\'{e}}e aux besoins d'int{\'{e}}gration pour des projets analogues.},
author = {Larmande, Pierre},
keywords = {Bio-MOBY,Data integration,G{\'{e}}nomique fonctionnelle v{\'{e}}g{\'{e}}tale,LE SELECT,Middleware Interoperability,Web services,bioinformatique,functional genomics,int{\'{e}}gration,m{\'{e}}diation,services Web},
month = {dec},
publisher = {Universite Montpellier 2},
title = {{Mutualiser et partager, un d{\'{e}}fi pour la g{\'{e}}nomique fonctionnelle v{\'{e}}g{\'{e}}tale}},
url = {https://tel.archives-ouvertes.fr/tel-01401210},
year = {2007}
}
@article{Belleau2008a,
abstract = {Presently, there are numerous bioinformatics databases available on different websites. Although RDF was proposed as a standard format for the web, these databases are still available in various formats. With the increasing popularity of the semantic web technologies and the ever growing number of databases in bioinformatics, there is a pressing need to develop mashup systems to help the process of bioinformatics knowledge integration. Bio2RDF is such a system, built from rdfizer programs written in JSP, the Sesame open source triplestore technology and an OWL ontology. With Bio2RDF, documents from public bioinformatics databases such as Kegg, PDB, MGI, HGNC and several of NCBI's databases can now be made available in RDF format through a unique URL in the form of http://bio2rdf.org/namespace:id. The Bio2RDF project has successfully applied the semantic web technology to publicly available databases by creating a knowledge space of RDF documents linked together with normalized URIs and sharing a common ontology. Bio2RDF is based on a three-step approach to build mashups of bioinformatics data. The present article details this new approach and illustrates the building of a mashup used to explore the implication of four transcription factor genes in Parkinson's disease. The Bio2RDF repository can be queried at http://bio2rdf.org.},
author = {Belleau, Fran{\c{c}}ois and Nolin, Marc-Alexandre and Tourigny, Nicole and Rigault, Philippe and Morissette, Jean},
doi = {10.1016/j.jbi.2008.03.004},
file = {:Users/plarmande/Documents/Mendeley Desktop/Belleau et al/Journal of biomedical informatics/Belleau et al.{\_}2008{\_}Bio2RDF towards a mashup to build bioinformatics knowledge systems.pdf:pdf},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Animals,Artificial Intelligence,Computational Biology,Computational Biology: methods,Database Management Systems,Humans,Information Dissemination,Information Dissemination: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Internet,Internet: utilization,Parkinson Disease,Parkinson Disease: genetics,Programming Languages,Semantics,Systems Integration,Terminology as Topic,Transcription Factors,Transcription Factors: analysis,Transcription Factors: metabolism,Vocabulary, Controlled},
month = {oct},
number = {5},
pages = {706--16},
pmid = {18472304},
title = {{Bio2RDF: towards a mashup to build bioinformatics knowledge systems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18472304},
volume = {41},
year = {2008}
}
@article{Antipolis2014,
author = {Michel, Franck and Montagnat, Johan and Faron-zucker, Catherine},
file = {:Users/plarmande/Documents/Mendeley Desktop/Michel, Montagnat, Faron-zucker/Unknown/Michel, Montagnat, Faron-zucker{\_}2014{\_}A survey of RDB to RDF translation approaches and tools.pdf:pdf},
keywords = {database integration,database semantics,rdb-to-rdf mapping,semantic web},
number = {May},
title = {{A survey of RDB to RDF translation approaches and tools}},
year = {2014}
}
@article{Otero-Cerdeira2015,
abstract = {The amount of research papers published nowadays related to ontology matching is remarkable and we believe that reflects the growing interest of the research community. However, for new practitioners that approach the field, this amount of information might seem overwhelming. Therefore, the purpose of this work is to help in guiding new practitioners get a general idea on the state of the field and to determine possible research lines. To do so, we first perform a literature review of the field in the last decade by means of an online search. The articles retrieved are sorted using a classification framework that we propose, and the different categories are revised and analyzed. The information in this review is extended and supported by the results obtained by a survey that we have designed and conducted among the practitioners.},
author = {Otero-Cerdeira, Lorena and Rodr{\'{i}}guez-Mart{\'{i}}nez, Francisco J. and G{\'{o}}mez-Rodr{\'{i}}guez, Alma},
doi = {10.1016/j.eswa.2014.08.032},
file = {:Users/plarmande/Documents/Mendeley Desktop/Otero-Cerdeira, Rodr{\'{i}}guez-Mart{\'{i}}nez, G{\'{o}}mez-Rodr{\'{i}}guez/Expert Systems with Applications/Otero-Cerdeira, Rodr{\'{i}}guez-Mart{\'{i}}nez, G{\'{o}}mez-Rodr{\'{i}}guez{\_}2015{\_}Ontology matching A literature review.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Classification framework,Literature review,Ontology matching,User survey},
number = {2},
pages = {949--971},
publisher = {Elsevier Ltd},
title = {{Ontology matching: A literature review}},
url = {http://dx.doi.org/10.1016/j.eswa.2014.08.032},
volume = {42},
year = {2015}
}
@article{Tranchevent2016a,
abstract = {Genomic studies and high-throughput experiments often produce large lists of candidate genes among which only a small fraction are truly relevant to the disease, phenotype or biological process of interest. Gene prioritization tackles this problem by ranking candidate genes by profiling candidates across multiple genomic data sources and integrating this heterogeneous information into a global ranking. We describe an extended version of our gene prioritization method, Endeavour, now available for six species and integrating 75 data sources. The performance (Area Under the Curve) of Endeavour on cross-validation benchmarks using 'gold standard' gene sets varies from 88{\%} (for human phenotypes) to 95{\%} (for worm gene function). In addition, we have also validated our approach using a time-stamped benchmark derived from the Human Phenotype Ontology, which provides a setting close to prospective validation. With this benchmark, using 3854 novel gene-phenotype associations, we observe a performance of 82{\%}. Altogether, our results indicate that this extended version of Endeavour efficiently prioritizes candidate genes. The Endeavour web server is freely available at https://endeavour.esat.kuleuven.be/.},
author = {Tranchevent, L{\'{e}}on Charles and Ardeshirdavani, Amin and ElShal, Sarah and Alcaide, Daniel and Aerts, Jan and Auboeuf, Didier and Moreau, Yves},
doi = {10.1093/nar/gkw365},
file = {:Users/plarmande/Documents/Mendeley Desktop/Tranchevent et al/Nucleic acids research/Tranchevent et al.{\_}2016{\_}Candidate gene prioritization with Endeavour.pdf:pdf},
isbn = {13624962 (Electronic)},
issn = {13624962},
journal = {Nucleic acids research},
number = {W1},
pages = {W117--W121},
pmid = {27131783},
title = {{Candidate gene prioritization with Endeavour}},
volume = {44},
year = {2016}
}
@article{Hassani-Pak2016,
abstract = {The chances of raising crop productivity to enhance global food security would be greatly improved if we had a complete understanding of all the biological mechanisms that underpinned traits such as crop yield, disease resistance or nutrient and water use efficiency. With more crop genomes emerging all the time, we are nearer having the basic information, at the gene-level, to begin assembling crop gene catalogues and using data from other plant species to understand how the genes function and how their interactions govern crop development and physiology. Unfortunately, the task of creating such a complete knowledge base of gene functions, interaction networks and trait biology is technically challenging because the relevant data are dispersed in myriad databases in a variety of data formats with variable quality and coverage. In this paper we present a general approach for building genome-scale knowledge networks that provide a unified representation of heterogeneous but interconnected datasets to enable effective knowledge mining and gene discovery. We describe the datasets and outline the methods, workflows and tools that we have developed for creating and visualising these networks for the major crop species, wheat and barley. We present the global characteristics of such knowledge networks and with an example linking a seed size phenotype to a barley WRKY transcription factor orthologous to TTG2 from Arabidopsis, we illustrate the value of integrated data in biological knowledge discovery. The software we have developed (www.ondex.org) and the knowledge resources (http://knetminer.rothamsted.ac.uk) we have created are all open-source and provide a first step towards systematic and evidence-based gene discovery in order to facilitate crop improvement.},
annote = {approach for building genome- scale knowledge networks that provide a unified representation of heterogeneous but interconnected datasets to enable effective knowledge mining and gene discovery

The generation of the hypotheses that link genotype to phenotype and the identification of the candidate biological pathways, processes and functional genes that could be involved requires the integration of multiple heterogeneous types of information. This information is spread across many different databases (Rigden et al., 2016) that can include known records of gene-phenotype links, gene-disease associations, gene expression and co-expression, allelic information andeffects of ge- netic variation, links to scientific literature, homology relations, protein- protein interactions, gene regulation, protein pathway memberships, gene-ontology annotations, protein-domain information and other do- main specific information.},
author = {Hassani-Pak, Keywan and Castellote, Martin and Esch, Maria and Hindle, Matthew and Lysenko, Artem and Taubert, Jan and Rawlings, Christopher},
doi = {10.1016/j.atg.2016.10.003},
file = {:Users/plarmande/Documents/Mendeley Desktop/Hassani-Pak et al/Applied {\&} Translational Genomics/Hassani-Pak et al.{\_}2016{\_}Developing integrated crop knowledge networks to advance candidate gene discovery.pdf:pdf},
issn = {22120661},
journal = {Applied {\&} Translational Genomics},
keywords = {Bioinformatics,Data integration,Gene discovery,Knowledge discovery, crop genomics,Knowledge network},
pages = {18--26},
publisher = {The Authors},
title = {{Developing integrated crop knowledge networks to advance candidate gene discovery}},
url = {http://dx.doi.org/10.1016/j.atg.2016.10.003},
volume = {11},
year = {2016}
}
@article{berners2001semweb,
author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora and Others},
journal = {Scientific american},
number = {5},
pages = {29--37},
publisher = {New York, NY, USA:},
title = {{The semantic web}},
volume = {284},
year = {2001}
}
@inproceedings{Zevio2016,
abstract = {The Agronomic Linked Data project (AgroLD) is a Semantic Web knowledge base designed to integrate data from various publicly available plant centric data sources. The aim of AgroLD project is to provide a portal for bioinformaticians and domain experts to exploit the homogenized data towards enabling to bridge the knowledge. Here we present new tools that enable "full text search" functionalities with Elastic clusters and enhance data annotation with ontologies.},
author = {Zevio, S. and {El Hassouni}, N. and Ruiz, M. and Larmande, P.},
booktitle = {CEUR Workshop Proceedings},
issn = {16130073},
keywords = {Elastic,Linked data,Plant molecular biology},
title = {{AgroLD indexing tools with ontological annotations}},
volume = {1795},
year = {2016}
}
@inproceedings{do:hal-01711331,
address = {Hanoi, Vietnam},
author = {Do, Huy and Tran, Hanh and {Khoat Than}, Quang and Larmande, Pierre},
booktitle = {CiCling},
keywords = {Text mining ; LSTM-CRF ; NER ; Bioinformatics ; Pl},
title = {{Comparative study of Named-Entity Recognition methods in the agronomical domain}},
url = {https://hal.archives-ouvertes.fr/hal-01711331},
year = {2018}
}
@article{Pugh2004a,
abstract = {A linkage map of cacao based on codominant markers has been constructed by integrating 201 new simple sequence repeats (SSR) developed in this study with a number of isoenzymes, restriction fragment length polymorphisms (RFLP), microsatellite markers and resistance and defence gene analogs (Rgenes-RFLP) previously mapped in cacao. A genomic library enriched for (GA)(n) and (CA)(n) was constructed, and 201 new microsatellite loci were mapped on 135 individuals from the same mapping population used to establish the first reference maps. This progeny resulted from a cross between two heterozygous cacao clones: an Upper-Amazon Forastero (UPA 402) and a Trinitario (UF 676). The new map contains 465 markers (268 SSRs, 176 RFLPs, five isoenzymes and 16 Rgenes-RFLP) arranged in ten linkage groups corresponding to the haploid chromosome number of cacao. Its length is 782.8 cM, with an average interval distance between markers of 1.7 cM. The new microsatellite markers were distributed throughout all linkage groups of the map, but their distribution was not random. The length of the map established with only SSRs was 769.6 cM, representing 94.8{\%} of the total map. The current level of genome coverage is approximately one microsatellite every 3 cM. This new reference map provides a set of useful markers that is transferable across different mapping populations and will allow the identification and comparison of the most important regions involved in the variation of the traits of interest and the development of marker-assisted selection strategies.},
author = {Pugh, T. and Fouet, O. and Risterucci, A. M. and Brottier, P. and Abouladze, M. and Deletrez, C. and Courtois, B. and Clement, D. and Larmande, P. and N'Goran, J. A K and Lanaud, C.},
doi = {10.1007/s00122-003-1533-4},
file = {:Users/plarmande/Documents/Mendeley Desktop/Pugh et al/Theor Appl Genet/Pugh et al.{\_}2004{\_}A new cacao linkage map based on codominant markers development and integration of 201 new microsatellite markers.html:html},
issn = {0040-5752},
journal = {Theor Appl Genet},
keywords = {Cacao,Cacao- Chromosome Mapping- Crosses,Chromosome Mapping,Crosses- Genetic,Genetic- DNA Primers- Genomic Library- Microsatell,Genetic- Polymorphism,Genomic Library,Microsatellite Repeats,Polymorphism- Genetic,Polymorphism- Restriction Fragment Length,Restriction Fragment Length},
mendeley-tags = {Cacao,Cacao- Chromosome Mapping- Crosses,Chromosome Mapping,Crosses- Genetic,Genetic- DNA Primers- Genomic Library- Microsatell,Genetic- Polymorphism,Genomic Library,Microsatellite Repeats,Polymorphism- Genetic,Polymorphism- Restriction Fragment Length,Restriction Fragment Length},
month = {apr},
number = {6},
pages = {1151--61},
shorttitle = {A new cacao linkage map based on codominant marker},
title = {{A new cacao linkage map based on codominant markers: development and integration of 201 new microsatellite markers}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14760486 http://www.ncbi.nlm.nih.gov/pubmed/14760486?dopt=AbstractPlus http://dx.doi.org/10.1007/s00122-003-1533-4},
volume = {108},
year = {2004}
}
@article{Manel2016,
author = {Manel, Achichi and Zohra, Belahsene and Konstantin, Todorov},
doi = {10.3166/isi.21.5-6.11-29},
issn = {16331311},
journal = {Ing{\'{e}}nierie des syst{\`{e}}mes d'information},
month = {dec},
number = {5-6},
pages = {11--29},
title = {{A survey on web data linking}},
url = {http://isi.revuesonline.com/article.jsp?articleId=37158},
volume = {21},
year = {2016}
}
@article{Moreau2012,
abstract = {Nature Reviews Genetics, (2012). doi:10.1038/nrg3253},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Moreau, Yves and Tranchevent, L{\'{e}}on Charles},
doi = {10.1038/nrg3253},
eprint = {NIHMS150003},
file = {:Users/plarmande/Documents/Mendeley Desktop/Moreau, Tranchevent/Nature Reviews Genetics/Moreau, Tranchevent{\_}2012{\_}Computational tools for prioritizing candidate genes Boosting disease gene discovery.pdf:pdf},
isbn = {1471-0064 (Electronic)$\backslash$r1471-0056 (Linking)},
issn = {14710056},
journal = {Nature Reviews Genetics},
number = {8},
pages = {523--536},
pmid = {22751426},
publisher = {Nature Publishing Group},
title = {{Computational tools for prioritizing candidate genes: Boosting disease gene discovery}},
url = {http://dx.doi.org/10.1038/nrg3253},
volume = {13},
year = {2012}
}
@article{Le2012,
abstract = {Finding genes associated with a disease is an important issue in the biomedical area and many gene prioritization methods have been proposed for this goal. Among these, network-based approaches are recently proposed and outperformed functional annotation-based ones. Here, we introduce a novel Cytoscape plug-in, GPEC, to help identify putative genes likely to be associated with specific diseases or pathways. In the plug-in, gene prioritization is performed through a random walk with restart algorithm, a state-of-the art network-based method, along with a gene/protein relationship network. The plug-in also allows users efficiently collect biomedical evidence for highly ranked candidate genes. A set of known genes, candidate genes and a gene/protein relationship network can be provided in a flexible way. {\textcopyright} 2012 Elsevier Ltd.},
author = {Le, Duc Hau and Kwon, Yung Keun},
doi = {10.1016/j.compbiolchem.2012.02.004},
file = {:Users/plarmande/Documents/Mendeley Desktop/Le, Kwon/Computational Biology and Chemistry/Le, Kwon{\_}2012{\_}GPEC A Cytoscape plug-in for random walk-based gene prioritization and biomedical evidence collection.pdf:pdf},
isbn = {1476-928X (Electronic)$\backslash$r1476-9271 (Linking)},
issn = {14769271},
journal = {Computational Biology and Chemistry},
keywords = {Biomedical evidence collection,Cytoscape plug-in,Gene prioritization,Random walk with restart algorithm},
pages = {17--23},
pmid = {22430954},
publisher = {Elsevier Ltd},
title = {{GPEC: A Cytoscape plug-in for random walk-based gene prioritization and biomedical evidence collection}},
url = {http://dx.doi.org/10.1016/j.compbiolchem.2012.02.004},
volume = {37},
year = {2012}
}
@article{Cohen-Boulakia2017,
abstract = {With the development of new experimental technologies, biologists are faced with an avalanche of data to be computationally analyzed for scientific advancements and discoveries to emerge. Faced with the complexity of analysis pipelines, the large number of computational tools, and the enormous amount of data to manage, there is compelling evidence that many if not most scientific discoveries will not stand the test of time: increasing the reproducibility of computed results is of paramount importance. The objective we set out in this paper is to place scientific workflows in the context of reproducibility. To do so, we define several kinds of reproducibility that can be reached when scientific workflows are used to perform experiments. We characterize and define the criteria that need to be catered for by reproducibility-friendly scientific workflow systems, and use such criteria to place several representative and widely used workflow systems and companion tools within such a framework. We also discuss the remaining challenges posed by reproducible scientific workflows in the life sciences. Our study was guided by three use cases from the life science domain involving in silico experiments.},
author = {Cohen-Boulakia, Sarah and Belhajjame, Khalid and Collin, Olivier and Chopard, J{\'{e}}r{\^{o}}me and Froidevaux, Christine and Gaignard, Alban and Hinsen, Konrad and Larmande, Pierre and Bras, Yvan Le and Lemoine, Fr{\'{e}}d{\'{e}}ric and Mareuil, Fabien and M{\'{e}}nager, Herv{\'{e}} and Pradal, Christophe and Blanchet, Christophe},
doi = {10.1016/j.future.2017.01.012},
issn = {0167739X},
journal = {Future Generation Computer Systems},
pages = {284--298},
title = {{Scientific workflows for computational reproducibility in the life sciences: Status, challenges and opportunities}},
volume = {75},
year = {2017}
}
@article{Habibi2017a,
author = {Habibi, Maryam and Weber, Leon and Neves, Mariana and Wiegandt, David Luis and Leser, Ulf},
doi = {10.1093/bioinformatics/btx228},
file = {:Users/plarmande/Documents/Mendeley Desktop/Habibi et al/Bioinformatics/Habibi et al.{\_}2017{\_}Deep learning with word embeddings improves biomedical named entity recognition.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
number = {14},
pages = {i37--i48},
title = {{Deep learning with word embeddings improves biomedical named entity recognition}},
volume = {33},
year = {2017}
}
@article{Lysenko2016,
abstract = {Systems biology experiments generate large volumes of data of multiple modalities and this information presents a challenge for integration due to a mix of complexity together with rich semantics. Here, we describe how graph databases provide a powerful framework for storage, querying and envisioning of biological data. We show how graph databases are well suited for the representation of biological information, which is typically highly connected, semi-structured and unpredictable. We outline an application case that uses the Neo4j graph database for building and querying a prototype network to provide biological context to asthma related genes. Our study suggests that graph databases provide a flexible solution for the integration of multiple types of biological data and facilitate exploratory data mining to support hypothesis generation.},
author = {Lysenko, Artem and Roznovăţ, Irina A. and Saqi, Mansoor and Mazein, Alexander and Rawlings, Christopher J and Auffray, Charles and Auffray, C and Charron, D and Hood, L and Hood, L and Tian, Q and Callahan, A and Cruz-Toledo, J and Ansell, P and Dumontier, M and K{\"{o}}hler, J and Baumbach, J and Taubert, J and Lysenko, A and Lysenko, A and Hindle, MM and Eronen, L and Toivonen, H and Tatusova, T and Ciufo, S and Fedorov, B and Sayers, EW and Barrett, T and Benson, DA and Bairoch, A and Kerrien, S and Aranda, B and Breuza, L and Croft, D and Mundo, AF and Haw, R and Bauer-Mehren, A and Bundschus, M and Rautschka, M and Knox, C and Law, V and Jewison, T and Uhl{\'{e}}n, M and Fagerberg, L and Hallstr{\"{o}}m, BM and Kaneko, Y and Yatagai, Y and Yamada, H and Voraphani, N and Gladwin, MT and Contreras, AU and Modena, BD and Tedrow, JR and Milosevic, J and Durrington, HJ and Farrow, SN and Loudon, AS and Ray, DW and Ko, CH and Takahashi, JS and Lesk, V and Taubert, J and Rawlings, C and Sternberg, MJE and Tamaddoni-Nezhad, A and Lesk, VI and C{\^{o}}t{\'{e}}, RA and Rogers, FB and Ashburner, M and Ball, CA and Blake, JA and Brinkman, R and Courtot, M and Derom, D and Smith, B and Ashburner, M and Rosse, C and Lassila, O and Swick, RR and Wide, W and Consortium, W},
doi = {10.1186/s13040-016-0102-8},
file = {:Users/plarmande/Documents/Mendeley Desktop/Lysenko et al/BioData Mining/Lysenko et al.{\_}2016{\_}Representing and querying disease networks using graph databases.pdf:pdf},
isbn = {1304001601},
issn = {1756-0381},
journal = {BioData Mining},
keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Data Mining and Knowledge Discovery},
number = {1},
pages = {23},
pmid = {27462371},
title = {{Representing and querying disease networks using graph databases}},
url = {http://biodatamining.biomedcentral.com/articles/10.1186/s13040-016-0102-8},
volume = {9},
year = {2016}
}
@article{TAGNY2016,
author = {TAGNY, Gildas and VENKATESAN, Aravind and {EL HASSOUNI}, Nordine and RUIZ, Manuel and LARMANDE, Pierre},
doi = {10.3166/isi.21.5-6.133-157},
journal = {Ing{\'{e}}nierie des Syst{\`{e}}mes d'Information},
number = {5-6},
pages = {133--157},
title = {{AgroLD API. Une architecture orient{\'{e}}e services pour l'extraction de connaissances dans la base de donn{\'{e}}es li{\'{e}}es AgroLD}},
volume = {21},
year = {2016}
}
@article{Have2013,
author = {Have, Christian Theil and Jensen, Lars Juhl},
doi = {10.1093/bioinformatics/btt549},
file = {:Users/plarmande/Documents/Mendeley Desktop/Have, Jensen/Unknown/Have, Jensen{\_}2013{\_}Databases and ontologies Are graph databases ready for bioinformatics.pdf:pdf},
number = {24},
pages = {3107--3108},
title = {{Databases and ontologies Are graph databases ready for bioinformatics ?}},
volume = {29},
year = {2013}
}
@incollection{Achichi2016,
author = {Achichi, Manel and {Ben Ellefi}, Mohamed and Symeonidou, Danai and Todorov, Konstantin},
booktitle = {20th International Conference on Knowledge Engineering and Knowledge Management - Volume 10024},
doi = {10.1007/978-3-319-49004-5_1},
isbn = {978-3-319-49003-8},
pages = {3--18},
publisher = {Springer-Verlag New York, Inc.},
title = {{Automatic Key Selection for Data Linking}},
url = {http://link.springer.com/10.1007/978-3-319-49004-5{\_}1},
year = {2016}
}
@article{Michel2015,
author = {Michel, Franck and Djimenou, Lo{\"{i}}c and Montagnat, Johan and Faron-zucker, Catherine},
file = {:Users/plarmande/Documents/Mendeley Desktop/Michel et al/Unknown/Michel et al.{\_}2015{\_}xR2RML Non-Relational Databases to RDF Mapping Language To cite this version xR2RML Non-Relational Databases to RD.pdf:pdf},
title = {{xR2RML : Non-Relational Databases to RDF Mapping Language To cite this version : xR2RML : Non-Relational Databases to RDF Mapping Language}},
year = {2015}
}
@article{BizerHeath2009,
author = {Bizer, Christian and Heath, T and Berners-Lee, T},
file = {:Users/plarmande/Documents/Mendeley Desktop/Bizer, Heath, Berners-Lee/International Journal on Semantic Web and Information Systems/Bizer, Heath, Berners-Lee{\_}2009{\_}Linked Data - The Story So Far.pdf:pdf},
journal = {International Journal on Semantic Web and Information Systems},
keywords = {Linked Data},
mendeley-tags = {Linked Data},
number = {3},
pages = {1--22},
publisher = {Elsevier},
title = {{Linked Data - The Story So Far}},
url = {http://www.citeulike.org/user/omunoz/article/5008761},
volume = {5},
year = {2009}
}
@article{Jupp2014,
abstract = {MOTIVATION: Resource description framework (RDF) is an emerging technology for describing, publishing and linking life science data. As a major provider of bioinformatics data and services, the European Bioinformatics Institute (EBI) is committed to making data readily accessible to the community in ways that meet existing demand. The EBI RDF platform has been developed to meet an increasing demand to coordinate RDF activities across the institute and provides a new entry point to querying and exploring integrated resources available at the EBI.

AVAILABILITY: http://www.ebi.ac.uk/rdf CONTACT: jupp@ebi.ac.uk.},
author = {Jupp, Simon and Malone, James and Bolleman, Jerven and Brandizi, Marco and Davies, Mark and Garcia, Leyla and Gaulton, Anna and Gehant, Sebastien and Laibe, Camille and Redaschi, Nicole and Wimalaratne, Sarala M and Martin, Maria and {Le Nov{\`{e}}re}, Nicolas and Parkinson, Helen and Birney, Ewan and Jenkinson, Andrew M},
doi = {10.1093/bioinformatics/btt765},
file = {:Users/plarmande/Documents/Mendeley Desktop/Jupp et al/Bioinformatics (Oxford, England)/Jupp et al.{\_}2014{\_}The EBI RDF platform linked open data for the life sciences.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
month = {jan},
pages = {1--2},
pmid = {24413672},
title = {{The EBI RDF platform: linked open data for the life sciences.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24413672},
year = {2014}
}
@article{Pareja-tobes2015,
author = {Pareja-tobes, Pablo and Tobes, Raquel and Manrique, Marina and Pareja, Eduardo and Pareja-tobes, Eduardo},
file = {:Users/plarmande/Documents/Mendeley Desktop/Pareja-tobes et al/Unknown/Pareja-tobes et al.{\_}2015{\_}Bio4j a high-performance cloud-enabled graph-based data platform.pdf:pdf},
pages = {1--11},
title = {{Bio4j : a high-performance cloud-enabled graph-based data platform}},
year = {2015}
}
@article{Gajendran2012,
author = {Gajendran, Santhosh Kumar},
file = {:Users/plarmande/Documents/Mendeley Desktop/Gajendran/University of Illinois/Gajendran{\_}2012{\_}A Survey on NoSQL Databases.pdf:pdf},
journal = {University of Illinois},
title = {{A Survey on NoSQL Databases}},
url = {http://www.masters.dgtu.donetsk.ua/2013/fknt/babich/library/article10.pdf},
year = {2012}
}
@techreport{Fielding1999,
abstract = {The Hypertext Transfer Protocol (HTTP) is an application-level protocol for distributed, collaborative, hypermedia information systems. It is a generic, stateless, protocol which can be used for many tasks beyond its use for hypertext, such as name servers and distributed object management systems, through extension of its request methods, error codes and headers [47]. A feature of HTTP is the typing and negotiation of data representation, allowing systems to be built independently of the data being transferred. HTTP has been in use by the World-Wide Web global information initiative since 1990. This specification defines the protocol referred to as "HTTP/1.1", and is an update to RFC 2068 [33].},
author = {Fielding, R. and Gettys, J. and Mogul, J. and Frystyk, H. and Masinter, L. and Leach, P. and Berners-Lee, Sir Tim},
institution = {The Internet Society},
keywords = {HTTP,RFC},
mendeley-tags = {HTTP,RFC},
title = {{RFC 2616: Hypertext Transfer Protocol -- HTTP/1.1}},
type = {RFC},
url = {http://tools.ietf.org/html/rfc2616},
year = {1999}
}
@article{Basaldella2017,
abstract = {Background: This article describes a high-recall, high-precision approach for the extraction of biomedical entities from scientific articles. Method: The approach uses a two-stage pipeline, combining a dictionary-based entity recognizer with a machine-learning classifier. First, the OGER entity recognizer,which has a bias towards high recall, annotates the terms that appear in selected domain ontologies. Subsequently, the Distiller framework uses this information as a feature for a machine learning algorithm to select the relevant entities only. For this step, we compare two different supervised machine-learning algorithms: Conditional Random Fields and Neural Networks. Results: In an in-domain evaluation using the CRAFT corpus, we test the performance of the combined systems when recognizing chemicals, cell types, cellular components, biological processes, molecular functions, organisms, proteins, and biological sequences. Our best system combines dictionary-based candidate generation with Neural-Network-based filtering. It achieves an overall precision of 86{\%} at a recall of 60{\%} on the named entity recognition task, and a precision of 51{\%} at a recall of 49{\%} on the concept recognition task. Conclusion: These results are to our knowledge the best reported so far in this particular task.},
author = {Basaldella, Marco and Furrer, Lenz and Tasso, Carlo and Rinaldi, Fabio},
doi = {10.1186/s13326-017-0157-6},
file = {:Users/plarmande/Documents/Mendeley Desktop/Basaldella et al/Journal of Biomedical Semantics/Basaldella et al.{\_}2017{\_}Entity recognition in the biomedical domain using a hybrid approach.pdf:pdf},
issn = {20411480},
journal = {Journal of Biomedical Semantics},
keywords = {Machine learning,Named entity recognition,Natural language processing,Text mining},
number = {1},
pages = {1--14},
publisher = {Journal of Biomedical Semantics},
title = {{Entity recognition in the biomedical domain using a hybrid approach}},
volume = {8},
year = {2017}
}
@article{Faria2013,
abstract = {AgreementMaker is one of the leading ontology matching systems, thanks to its combination of a flexible and extensible framework with a comprehensive user interface. In many domains, such as the biomedical, ontologies are becoming increasingly large thus presenting new challenges. We have developed a new core framework, AgreementMakerLight, focused on computational efficiency and designed to handle very large ontologies, while preserving most of the flexibility and extensibility of the original AgreementMaker framework. We evaluated the efficiency of AgreementMakerLight in two OAEI tracks: Anatomy and Large Biomedical Ontologies, obtaining excellent run time results. In addition, for the Anatomy track, AgreementMakerLight is now the best system as measured in terms of F-measure. Also in terms of F-measure, AgreementMakerLight is competitive with the best OAEI performers in two of the three tasks of the Large Biomedical Ontologies track that match whole ontologies.},
author = {Faria, Daniel and Pesquita, Catia and Santos, Emanuel and Palmonari, Matteo and Cruz, Isabel F. and Couto, Francisco M.},
doi = {10.1007/978-3-642-41030-7_38},
file = {:Users/plarmande/Documents/Mendeley Desktop/Faria et al/Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)/Faria et al.{\_}2013{\_}The AgreementMakerLight ontology matching system.pdf:pdf},
isbn = {9783642410291},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {527--541},
title = {{The AgreementMakerLight ontology matching system}},
volume = {8185 LNCS},
year = {2013}
}
@article{Patnala2013,
abstract = {The candidate gene approach has been a pioneer in the field of genetic epidemiology, identifying risk alleles and their association with clinical traits. With the advent of rapidly changing technology, there has been an explosion of in silico tools available to researchers, giving them fast, efficient resources and reliable strategies important to find casual gene variants for candidate or genome wide association studies (GWAS). In this review, following a description of candidate gene prioritisation, we summarise the approaches to single nucleotide polymorphism (SNP) prioritisation and discuss the tools available to assess functional relevance of the risk variant with consideration to its genomic location. The strategy and the tools discussed are applicable to any study investigating genetic risk factors associated with a particular disease. Some of the tools are also applicable for the functional validation of variants relevant to the era of GWAS and next generation sequencing (NGS).},
author = {Patnala, Radhika and Clements, Judith and Batra, Jyotsna and Kwon, JM and Goate, AM and Collins, FS and Guyer, MS and Chakravarti, A and Peters, BJM and Rodin, AS and Boer, A De and der Zee, A-H Maitland-van and Burdick, KE and DeRosse, P and Kane, JM and Lencz, T and Malhotra, AK and Gibbs, RA and Belmont, JW and Hardenbol, P and Willis, TD and Yu, F and Yang, H and Ch'ang, L-Y and Huang, W and Liu, B and Shen, Y and Pharoah, PDP and Dunning, AM and Ponder, BAJ and Easton, DF and Braem, MGM and Schouten, LJ and Peeters, PHM and den Brandt, PA and Onland-Moret, NC and Tabor, HK and Risch, NJ and Myers, RM and Fern{\'{a}}ndez, J and Hoffmann, R and Valencia, A and Hokamp, K and Wolfe, KH and Mastellos, D and Andronis, C and Persidis, A and Lambris, JD and Croft, D and O'Kelly, G and Wu, G and Haw, R and Gillespie, M and Matthews, L and Caudy, M and Garapati, P and Gopinath, G and Jassal, B and Frisch, M and Klocke, B and Haltmeier, M and Frech, K and Kandasamy, K and Mohan, SS and Raju, R and Keerthikumar, S and Kumar, G and Venugopal, A and Telikicherla, D and Navarro, JD and Mathivanan, S and Pecquet, C and Haibe-Kains, B and Olsen, C and Djebbari, A and Bontempi, G and Correll, M and Bouton, C and Quackenbush, J and Chen, J and Bardes, EE and Aronow, BJ and Jegga, AG and Tranchevent, L-C and Capdevila, FB and Nitsch, D and Moor, B De and Causmaecker, P De and Moreau, Y and Amberger, J and Bocchini, C and Hamosh, A and Radivojac, P and Peng, K and Clark, WT and Peters, BJ and Mohan, A and Boyle, SM and Mooney, SD and Rhodes, DR and Kalyana-Sundaram, S and Mahavisno, V and Varambally, R and Yu, J and Briggs, BB and Barrette, TR and Anstet, MJ and Kincead-Beal, C and Kulkarni, P and Hu, P and Bader, G and Wigle, DA and Emili, A and Wheeler, DL and Barrett, T and Benson, DA and Bryant, SH and Canese, K and Church, DM and DiCuccio, M and Edgar, R and Federhen, S and Helmberg, W and Hubbard, TJP and Aken, BL and Ayling, S and Ballester, B and Beal, K and Bragin, E and Brent, S and Chen, Y and Clapham, P and Clarke, L and Batra, J and Nagle, C and O'Mara, T and Higgins, M and Dong, Y and Tan, O and Lose, F and Skeie, L and Srinivasan, S and Bolton, K and Narla, G and DiFeo, A and Reeves, HL and Schaid, DJ and Hirshfeld, J and Hod, E and Katz, A and Isaacs, WB and Hebbring, S and Komiya, A and Thierry-Mieg, D and Thierry-Mieg, J and Kuhn, RM and Karolchik, D and Zweig, AS and Wang, T and Smith, KE and Rosenbloom, KR and Rhead, B and Raney, BJ and Pohl, A and Pheasant, M and The, EPC and Frazer, KA and Pachter, L and Poliakov, A and Rubin, EM and Dubchak, I and Visel, A and Minovitsky, S and Dubchak, I and Pennacchio, LA and Lukashin, I and Novichkov, P and Boffelli, D and Paciorkowski, AR and Minovitsky, S and Yang, S and Dubchak, I and Chen, Y-H and Liu, C-K and Chang, S-C and Lin, Y-J and Tsai, M-F and Chen, Y-T and Yao, A and Mooney, SD and Krishnan, VG and Evani, US and Batra, J and O'Mara, T and Patnala, R and Lose, F and Clements, JA and Coassin, S and Brandst{\"{a}}tter, A and Kronenberg, F and Sherry, ST and Ward, M-H and Kholodov, M and Baker, J and Phan, L and Smigielski, EM and Sirotkin, K and Church, DM and Lappalainen, I and Sneddon, TP and Hinton, J and Maguire, M and Lopez, J and Garner, J and Paschall, J and DiCuccio, M and Yaschenko, E and Chen, K and McLellan, MD and Ding, L and Wendl, MC and Kasai, Y and Wilson, RK and Mardis, ER and Saccone, SF and Quan, J and Jones, PL and Saccone, SF and Quan, J and Mehta, G and Bolze, R and Thomas, P and Deelman, E and Tischfield, JA and Rice, JP and Riva, A and Kohane, IS and Andersen, MC and Engstr{\"{o}}m, PG and Lithwick, S and Arenillas, D and Eriksson, P and Lenhard, B and Wasserman, WW and Odeberg, J and Packer, BR and Yeager, M and Staats, B and Welch, R and Crenshaw, A and Kiley, M and Eckert, A and Beerman, M and Miller, E and Bergen, A and Wang, K and Li, M and Hakonarson, H and Xu, Z and Taylor, JA and Weiss, KM and Clark, AG and Ardlie, KG and Kruglyak, L and Seielstad, M and Slatkin, M and Pallej{\`{a}}, A and Horn, H and Eliasson, S and Jensen, LJ and Lawrence, R and Day-Williams, A and Mott, R and Broxholme, J and Cardon, L and Zeggini, E and Yoo, J and Lee, Y and Kim, Y and Rha, S and Kim, Y and Johnson, AD and Handsaker, RE and Pulit, SL and Nizzari, MM and O'Donnell, CJ and de Bakker, PIW and Barrett, JC and Fry, B and Maller, J and Daly, MJ and Jackson, DG and Healy, MD and Davison, DB and Maurano, MT and Humbert, R and Rynes, E and Thurman, RE and Haugen, E and Wang, H and Reynolds, AP and Sandstrom, R and Qu, H and Brody, J and Wang, X and Tomso, DJ and Liu, X and Bell, DA and Prokunina, L and Alarc{\'{o}}n-Riquelme, ME and GuhaThakurta, D and Xie, T and Anand, M and Edwards, S and Li, G and Wang, S and Schadt, E and Muinos-Gimeno, M and Montfort, M and Bayes, M and Estivill, X and Espinosa-Parrilla, Y and McLaren, W and Pritchard, B and Rios, D and Chen, Y and Flicek, P and Cunningham, F and Cooper, GM and Shendure, J and Jiang, L and Zhang, C and Li, Y and Yu, X and Zheng, J and Zou, P and Li, Y and Bin, X and Lu, J and Zhou, Y and Yue, P and Melamud, E and Moult, J and Ryan, M and Diekhans, M and Lien, S and Liu, Y and Karchin, R and Pieper, U and Webb, BM and Barkan, DT and Schneidman-Duhovny, D and Schlessinger, A and Braberg, H and Yang, Z and Meng, EC and Pettersen, EF and Huang, CC and Jegga, AG and Gowrisankar, S and Chen, J and Aronow, BJ and Baets, G De and Durme, J Van and Reumers, J and Maurer-Stroh, S and Vanhee, P and Dopazo, J and Schymkowitz, J and Rousseau, F and Conde, L and Vaquerizas, JM and Dopazo, H and Arbiza, L and Reumers, J and Rousseau, F and Schymkowitz, J and Dopazo, J and Mah, JTL and Low, ESH and Lee, E and Mah, JTL and Low, ESH and Lee, E and Miller, MP and Kumar, S and Kwasigroch, JM and Gilis, D and Dehouck, Y and Rooman, M and Mort, M and Evani, US and Krishnan, VG and Kamati, KK and Baenziger, PH and Bagchi, A and Peters, BJ and Sathyesh, R and Li, B and Sun, Y and Sunyaev, S and Ramensky, V and Bork, P and Adzhubei, IA and Schmidt, S and Peshkin, L and Ramensky, VE and Gerasimova, A and Bork, P and Kondrashov, AS and Sunyaev, SR and Kumar, P and Henikoff, S and Ng, PC and Choi, Y and Sims, GE and Murphy, S and Miller, JR and Chan, AP and Li, S and Iakoucheva, LM and Mooney, SD and Radivojac, P and Mann, M and Jensen, ON and Blom, N and Gammeltoft, S and Brunak, S and Sigrist, CJA and Cerutti, L and de Castro, E and Langendijk-Genevaux, PS and Bulliard, V and Bairoch, A and Hulo, N and Werner, T and Boyle, AP and Davis, S and Shulha, HP and Meltzer, P and Margulies, EH and Weng, Z and Furey, TS and Crawford, GE and Gaspar-Maia, A and Alajem, A and Meshorer, E and Ramalho-Santos, M and Tsunoda, T and Takagi, T and Cartharius, K and Frech, K and Grote, K and Klocke, B and Haltmeier, M and Klingenhoff, A and Frisch, M and Bayerlein, M and Werner, T and Heinemeyer, T and Wingender, E and Reuter, I and Hermjakob, H and Kel, AE and Kel, OV and Ignatieva, EV and Ananko, EA and Podkolodnaya, OA and Kolpakov, FA and Marinescu, VD and Kohane, IS and Riva, A and Macintyre, G and Bailey, J and Haviv, I and Kowalczyk, A and Boyle, AP and Hong, EL and Hariharan, M and Cheng, Y and Schaub, MA and Kasowski, M and Karczewski, KJ and Park, J and Hitz, BC and Weng, S and Coetzee, SG and Rhie, SK and Berman, BP and Coetzee, GA and Noushmehr, H and Hazelett, DJ and Coetzee, SG and Coetzee, GA and Risch, HA and Bajic, VB and Tan, SL and Chong, A and Tang, S and Str{\"{o}}m, A and Gustafsson, J-{\AA} and Lin, C-Y and Liu, ET and Portales-Casamar, E and Thongjuea, S and Kwon, AT and Arenillas, D and Zhao, X and Valen, E and Yusuf, D and Lenhard, B and Wasserman, WW and Sandelin, A and Frith, MC and Hansen, U and Weng, Z and Freedman, ML and Monteiro, ANA and Gayther, SA and Coetzee, GA and Risch, A and Plass, C and Casey, G and Biasi, M De and Carlson, C and Duggan, D and Mishra, PJ and Mishra, PJ and Banerjee, D and Bertino, JR and Sun, G and Yan, J and Noltner, K and Feng, J and Li, H and Sarkis, DA and Sommer, SS and Rossi, JJ and Davis-Dusenbery, BN and Hata, A and Betel, D and Wilson, M and Gabow, A and Marks, DS and Sander, C and Kozomara, A and Griffiths-Jones, S and Thomas, LF and Saito, T and S{\ae}trom, P and Liu, C and Zhang, F and Li, T and Lu, M and Wang, L and Yue, W and Zhang, D and Betel, D and Koppal, A and Agius, P and Sander, C and Leslie, C and Ziebarth, JD and Bhattacharya, A and Chen, A and Cui, Y and Hiard, S and Charlier, C and Coppieters, W and Georges, M and Baurain, D and Gilad, Y and Rifkin, SA and Pritchard, JK and Jansen, RC and Nap, J-P and Jansen, RC and Wu, C and Delano, DL and Mitro, N and Su, SV and Janes, J and McClurg, P and Batalov, S and Welch, GL and Zhang, J and Orth, AP and Wittkopp, PJ and Li, H and Deng, H and Mueller, M and Goel, A and Thimma, M and Dickens, NJ and Aitman, TJ and Mangion, J and Wang, J and Williams, R and Manly, K and Seaton, G and Haley, CS and Knott, SA and Kearsey, M and Visscher, PM and Zou, W and Aylor, D and Zeng, Z-B and Gatti, DM and Shabalin, AA and Lam, T-C and Wright, FA and Rusyn, I and Nobel, AB and Lee, S-I and Dudley, AM and Drubin, D and Silver, PA and Krogan, NJ and Pe'er, D and Koller, D and Giacomini, KM and Brett, CM and Altman, RB and Benowitz, NL and Dolan, ME and Flockhart, DA and Johnson, JA and Hayes, DF and Klein, T and Krauss, RM and Hawkins, RD and Hon, GC and Ren, B and Horgan, R and Kenny, L and Cartegni, L and Wang, J and Zhu, Z and Zhang, MQ and Krainer, AR and Smith, PJ and Zhang, C and Wang, J and Chew, SL and Zhang, MQ and Krainer, AR and Goren, A and Ram, O and Amit, M and Keren, H and Lev-Maor, G and Vig, I and Pupko, T and Ast, G and Wang, Z and Rolish, ME and Yeo, G and Tung, V and Mawson, M and Burge, CB and Zhang, XH-F and Chasin, LA and Fairbrother, WG and Yeh, R-F and Sharp, PA and Burge, CB and Desmet, F-O and Hamroun, D and Lalande, M and Collod-B{\'{e}}roud, G and Claustres, M and B{\'{e}}roud, C and Yang, J Ok and Kim, W-Y and Bhak, J and Ahmed, F and Kumar, M and Raghava, GPS and Tabaska, JE and Zhang, MQ and Zuker, M and Reeder, J and Steffen, P and Giegerich, R and Reeder, J and H{\"{o}}chsmann, M and Rehmsmeier, M and Voss, B and Giegerich, R and Lambert, A and Fontaine, J-F and Legendre, M and Leclerc, F and Permal, E and Major, F and Putzer, H and Delfour, O and Michot, B and Gautheret, D},
doi = {10.1186/1471-2156-14-39},
file = {:Users/plarmande/Documents/Mendeley Desktop/Patnala et al/BMC Genetics/Patnala et al.{\_}2013{\_}Candidate gene association studies a comprehensive guide to useful in silico tools.pdf:pdf},
isbn = {1471-2156 (Electronic)$\backslash$n1471-2156 (Linking)},
issn = {1471-2156},
journal = {BMC Genetics},
keywords = {Animal Genetics and Genomics,Genetics and Population Dynamics,Life Sciences,Microbial Genetics and Genomics,Plant Genetics {\&} Genomics,general},
number = {1},
pages = {39},
pmid = {23656885},
title = {{Candidate gene association studies: a comprehensive guide to useful in silico tools}},
url = {http://bmcgenet.biomedcentral.com/articles/10.1186/1471-2156-14-39},
volume = {14},
year = {2013}
}
@article{ElShal2016,
abstract = {Disease-gene identification is a challenging process that has multiple applications within functional genomics and personalized medicine. Typically, this process involves both finding genes known to be associated with the disease (through literature search) and carrying out preliminary experiments or screens (e.g. linkage or association studies, copy number analyses, expression profiling) to determine a set of promising candidates for experimental validation. This requires extensive time and monetary resources. We describe Beegle, an online search and discovery engine that attempts to simplify this process by automating the typical approaches. It starts by mining the literature to quickly extract a set of genes known to be linked with a given query, then it integrates the learning methodology of Endeavour (a gene prioritization tool) to train a genomic model and rank a set of candidate genes to generate novel hypotheses. In a realistic evaluation setup, Beegle has an average recall of 84{\%} in the top 100 returned genes as a search engine, which improves the discovery engine by 12.6{\%} in the top 5{\%} prioritized genes. Beegle is publicly available at http://beegle.esat.kuleuven.be/.},
author = {ElShal, Sarah and Tranchevent, L{\'{e}}on Charles and Sifrim, Alejandro and Ardeshirdavani, Amin and Davis, Jesse and Moreau, Yves},
doi = {10.1093/nar/gkv905},
file = {:Users/plarmande/Documents/Mendeley Desktop/ElShal et al/Nucleic Acids Research/ElShal et al.{\_}2016{\_}Beegle From literature mining to disease-gene discovery.pdf:pdf},
isbn = {1362-4962; 0305-1048},
issn = {13624962},
journal = {Nucleic Acids Research},
number = {2},
pages = {e18},
pmid = {26384564},
title = {{Beegle: From literature mining to disease-gene discovery}},
volume = {44},
year = {2016}
}
@article{Le2013,
abstract = {Background: Finding candidate genes associated with a disease is an important issue in biomedical research. Recently, many network-based methods have been proposed that implicitly utilize the modularity principle, which states that genes causing the same or similar diseases tend to form physical or functional modules in gene/protein relationship networks. Of these methods, the random walk with restart (RWR) algorithm is considered to be a state-of-the-art approach, but the modularity principle has not been fully considered in traditional RWR approaches. Therefore, we propose a novel method called ORIENT (neighbor-favoring weight reinforcement) to improve the performance of RWR through proper intensification of the weights of interactions close to the known disease genes. Results: Through extensive simulations over hundreds of diseases, we observed that our approach performs better than the traditional RWR algorithm. In particular, our method worked best when the weights of interactions involving only the nearest neighbor genes of the disease genes were intensified. Interestingly, the performance of our approach was negatively related to the probability with which the random walk will restart, whereas the performance of RWR without the weight-reinforcement was positively related in dense gene/protein relationship networks. We further found that the density of the disease gene-projected sub-graph and the number of paths between the disease genes in a gene/protein relationship network may be explanatory variables for the RWR performance. Finally, a comparison with other well-known gene prioritization tools including Endeavour, ToppGene, and BioGraph, revealed that our approach shows significantly better performance. Conclusion: Taken together, these findings provide insight to efficiently guide RWR in disease gene prioritization. {\textcopyright} 2013 Elsevier Ltd.},
author = {Le, Duc Hau and Kwon, Yung Keun},
doi = {10.1016/j.compbiolchem.2013.01.001},
file = {:Users/plarmande/Documents/Mendeley Desktop/Le, Kwon/Computational Biology and Chemistry/Le, Kwon{\_}2013{\_}Neighbor-favoring weight reinforcement to improve random walk-based disease gene prioritization.pdf:pdf},
isbn = {1476-9271},
issn = {14769271},
journal = {Computational Biology and Chemistry},
keywords = {Gene prioritization,Random walk with restart algorithm,Weight reinforcement},
pages = {1--8},
pmid = {23434623},
publisher = {Elsevier Ltd},
title = {{Neighbor-favoring weight reinforcement to improve random walk-based disease gene prioritization}},
url = {http://dx.doi.org/10.1016/j.compbiolchem.2013.01.001},
volume = {44},
year = {2013}
}
@article{Jonquet2018,
abstract = {Many vocabularies and ontologies are produced to represent and annotate agronomic data. However, those ontologies are spread out, in different formats, of different size, with different structures and from overlapping domains. Therefore, there is need for a common platform to receive and host them, align them, and enabling their use in agro-informatics applications. By reusing the National Center for Biomedical Ontologies (NCBO) BioPortal technology, we have designed AgroPortal, an ontology repository for the agronomy domain. The AgroPortal project re-uses the biomedical domain's semantic tools and insights to serve agronomy, but also food, plant, and biodiversity sciences. We offer a portal that features ontology hosting, search, versioning, visualization, comment, and recommendation; enables semantic annotation; stores and exploits ontology alignments; and enables interoperation with the semantic web. The AgroPortal specifically satisfies requirements of the agronomy community in terms of ontology formats (e.g., SKOS vocabularies and trait dictionaries) and supported features (offering detailed metadata and advanced annotation capabilities). In this paper, we present our platform's content and features, including the additions to the original technology, as well as preliminary outputs of five driving agronomic use cases that participated in the design and orientation of the project to anchor it in the community. By building on the experience and existing technology acquired from the biomedical domain, we can present in AgroPortal a robust and feature-rich repository of great value for the agronomic domain.},
author = {Jonquet, Cl{\'{e}}ment and Toulet, Anne and Arnaud, Elizabeth and Aubin, Sophie and {Dzal{\'{e}} Yeumo}, Esther and Emonet, Vincent and Graybeal, John and Laporte, Marie Ang{\'{e}}lique and Musen, Mark A. and Pesce, Valeria and Larmande, Pierre},
doi = {10.1016/j.compag.2017.10.012},
file = {:Users/plarmande/Documents/Mendeley Desktop/Jonquet et al/Computers and Electronics in Agriculture/Jonquet et al.{\_}2018{\_}AgroPortal A vocabulary and ontology repository for agronomy.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Agronomy,Biodiversity,Controlled vocabularies,Food,Knowledge organization systems or artifacts,Mapping,Metadata,Ontologies,Ontology repository,Plant sciences,Recommendation,Semantic annotation},
number = {October 2016},
pages = {126--143},
title = {{AgroPortal: A vocabulary and ontology repository for agronomy}},
volume = {144},
year = {2018}
}
@article{Wilkinson2016a,
abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders-representing academia, industry, funding agencies, and scholarly publishers-have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and {da Silva Santos}, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Merc{\`{e}} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J.G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and a.C {'t Hoen}, Peter and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris a. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
doi = {10.1038/sdata.2016.18},
file = {:Users/plarmande/Documents/Mendeley Desktop/Wilkinson et al/Scientific Data/Wilkinson et al.{\_}2016{\_}The FAIR Guiding Principles for scientific data management and stewardship.pdf:pdf},
issn = {2052-4463},
journal = {Scientific Data},
pages = {160018},
pmid = {26978244},
title = {{The FAIR Guiding Principles for scientific data management and stewardship}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4792175{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2016}
}
